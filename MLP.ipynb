{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow 2.2.2\n",
    "#others newest\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import tqdm.keras as tk\n",
    "from tqdm.keras import TqdmCallback\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "#from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./new_train/new_train\"\n",
    "test_path = \"./new_val_in/new_val_in\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator_x(training_list, batch_size):\n",
    "    index = 0\n",
    "    print(len(training_list))\n",
    "    while True:\n",
    "#         train_x = np.empty((batch_size,19))\n",
    "        train_x = np.empty((batch_size,38))\n",
    "        train_y = np.empty((batch_size,30))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            train_path = training_list[index]\n",
    "            with open(train_path, 'rb') as f:\n",
    "                data = pickle.load(f)                \n",
    "                agent_id = data['agent_id']\n",
    "                idx = np.where(data[\"track_id\"] == data[\"agent_id\"])[0][0]\n",
    "                \n",
    "                # choose a random number between 0 and the target agent idx\n",
    "                idx = random.randint(0, idx)\n",
    "                \n",
    "                #position\n",
    "                input_pos_in_data = data['p_in'][idx,:,:]                \n",
    "                input_pos_in_x = (input_pos_in_data[:,0]).reshape(1,19)\n",
    "                \n",
    "#                 train_x[i,:] = input_pos_in_x\n",
    "                \n",
    "                #velocity\n",
    "                input_vel_in_data = data['v_in'][idx,:,:]                \n",
    "                input_vel_in_x = (input_vel_in_data[:,0]).reshape(1,19)\n",
    "                \n",
    "                #Combine position and velocity together into (1,38)\n",
    "                input_combine_x = np.concatenate((input_pos_in_x, input_vel_in_x), axis=0).reshape(1,38)\n",
    "                \n",
    "#                 city <-- shape(1,39)\n",
    "#                 input_city = data['city']\n",
    "#                 if input_city == \"PIT\":\n",
    "#                     input_combine_x = np.append(input_combine_x, -1)\n",
    "#                 elif input_city == \"MIA\":\n",
    "#                     input_combine_x = np.append(input_combine_x, 1)\n",
    "                      \n",
    "                        \n",
    "                #train_x[i,:] = input_combine_x   #shape = (1,39)\n",
    "                \n",
    "                #input_combine_x = input_combine_x.reshape(1,39)\n",
    "                \n",
    "                #--------------------------Lane Info--------------------------\n",
    "                \n",
    "#                 # Find the closest lane with the corresponding lane_norm\n",
    "#                 input_lane = data['lane']\n",
    "#                 input_lane_norm = data['lane_norm']\n",
    "#                 num_lane = input_lane.shape[0]\n",
    "#                 closest_lane_idx = -2\n",
    "                \n",
    "#                 # Initialize distance = +inf\n",
    "#                 cur_distance = float('inf')\n",
    "                \n",
    "#                 # Start Iterating\n",
    "#                 for time_step in range(19):\n",
    "#                     for lane_idx in range(num_lane):\n",
    "#                         diff_x = data['p_in'][idx,time_step,0] - input_lane[lane_idx,0]\n",
    "#                         diff_y = data['p_in'][idx,time_step,1] - input_lane[lane_idx,1]\n",
    "#                         temp = diff_x ** 2 + diff_y ** 2\n",
    "#                         if temp < cur_distance:\n",
    "#                             cur_distance = temp\n",
    "#                             closest_lane_idx = lane_idx\n",
    "                    \n",
    "#                     #Put lane_x position and lane_x_velocity into the input feature \n",
    "#                     input_combine_x = np.append(input_combine_x, input_lane[closest_lane_idx,0])\n",
    "#                     input_combine_x = np.append(input_combine_x, input_lane_norm[closest_lane_idx,0])\n",
    "                    \n",
    "                #-----Now input feature shape = (1,77)\n",
    "                    \n",
    "                            \n",
    "                            \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "#                 # add number of lanes in input feature \n",
    "#                 input_lane = data['lane']\n",
    "#                 num_lanes = input_lane.shape[0]     # num_lanes = k\n",
    "#                 input_combine_x = np.append(input_combine_x, num_lanes)           #shape = (1,40)\n",
    "#                 input_combine_x = input_combine_x.reshape(1,40)\n",
    "                \n",
    "                \n",
    "#                 #add lane info of x-coordinate in input feature\n",
    "#                 temp_lane_arr = [0] * 1299\n",
    "#                 for k in range(1299):\n",
    "#                     if k == num_lanes:\n",
    "#                         break\n",
    "#                     temp_lane_arr[k] = input_lane[k,0]\n",
    "                \n",
    "#                 temp_input = input_combine_x.flatten()              \n",
    "#                 input_combine_x = np.append(temp_input,temp_lane_arr).reshape(1,1339) \n",
    "                \n",
    "                \n",
    "#                 #add lane norm info of x-coordinate in input feature\n",
    "#                 input_lane = data['lane_norm']\n",
    "#                 temp_lane_norm_arr = [0] * 1299\n",
    "#                 for k in range(1299):\n",
    "#                     if k == num_lanes:\n",
    "#                         break\n",
    "#                     temp_lane_norm_arr[k] = input_lane[k,0]            \n",
    "                \n",
    "#                 temp_input = input_combine_x.flatten()              \n",
    "#                 input_combine_x = np.append(temp_input,temp_lane_norm_arr).reshape(1,2638) \n",
    "                \n",
    "                train_x[i,:] = input_combine_x            \n",
    "                \n",
    "                output_pos_out_data = data['p_out'][idx,:,:]\n",
    "                output_pos_out_x = (output_pos_out_data[:,0]).reshape(1,30)\n",
    "                train_y[i,:] = output_pos_out_x\n",
    "            index += 1\n",
    "            \n",
    "        if index == len(training_list):\n",
    "            index = 0\n",
    "        yield train_x, train_y\n",
    "\n",
    "def valid_generator_x(valid_list, batch_size):\n",
    "    print(\"we are in vad\")\n",
    "    index = 0\n",
    "    while True:\n",
    "        valid_x = np.empty((batch_size,38))\n",
    "        valid_y = np.empty((batch_size,30))\n",
    "        for i in range(batch_size):\n",
    "            valid_path = valid_list[index]\n",
    "            with open(valid_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                agent_id = data['agent_id']\n",
    "                idx = np.where(data[\"track_id\"] == data[\"agent_id\"])[0][0]\n",
    "                \n",
    "                # choose a random number between 0 and the target agent idx\n",
    "                idx = random.randint(0, idx)\n",
    "                \n",
    "                \n",
    "                input_data = data['p_in'][idx,:,:]\n",
    "                input_pos_in_x = (input_data[:,0]).reshape(1,19)\n",
    "#                 valid_x[i,:] = input_data1\n",
    "                \n",
    "                #velocity\n",
    "                input_vel_in_data = data['v_in'][idx,:,:]                \n",
    "                input_vel_in_x = (input_vel_in_data[:,0]).reshape(1,19)\n",
    "                \n",
    "                #Combine position and velocity together into (1,38)\n",
    "                input_combine_x = np.concatenate((input_pos_in_x, input_vel_in_x), axis=0).reshape(1,38)\n",
    "                \n",
    "                # add city\n",
    "#                 input_city = data['city']\n",
    "#                 if input_city == \"PIT\":\n",
    "#                     input_combine_x = np.append(input_combine_x, -1)\n",
    "#                 elif input_city == \"MIA\":\n",
    "#                     input_combine_x = np.append(input_combine_x, 1)\n",
    "               \n",
    "                 #input_combine_x = input_combine_x.reshape(1,39)\n",
    "\n",
    "                \n",
    "#                 #--------------------------Lane Info--------------------------\n",
    "                \n",
    "#                 # Find the closest lane with the corresponding lane_norm\n",
    "#                 input_lane = data['lane']\n",
    "#                 input_lane_norm = data['lane_norm']\n",
    "#                 num_lane = input_lane.shape[0]\n",
    "#                 closest_lane_idx = -2\n",
    "                \n",
    "#                 # Initialize distance = +inf\n",
    "#                 cur_distance = float('inf')\n",
    "                \n",
    "#                 # Start Iterating\n",
    "#                 for time_step in range(19):\n",
    "#                     for lane_idx in range(num_lane):\n",
    "#                         diff_x = data['p_in'][idx,time_step,0] - input_lane[lane_idx,0]\n",
    "#                         diff_y = data['p_in'][idx,time_step,1] - input_lane[lane_idx,1]\n",
    "#                         temp = diff_x ** 2 + diff_y ** 2\n",
    "#                         if temp < cur_distance:\n",
    "#                             cur_distance = temp\n",
    "#                             closest_lane_idx = lane_idx\n",
    "                    \n",
    "#                     #Put lane_x position and lane_x_velocity into the input feature \n",
    "#                     input_combine_x = np.append(input_combine_x, input_lane[closest_lane_idx,0])\n",
    "#                     input_combine_x = np.append(input_combine_x, input_lane_norm[closest_lane_idx,0])\n",
    "                    \n",
    "#                 #-----Now input feature shape = (1,77)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "#                 # add number of lanes in input feature \n",
    "#                 input_lane = data['lane']\n",
    "#                 num_lanes = input_lane.shape[0]     # num_lanes = k\n",
    "#                 input_combine_x = np.append(input_combine_x, num_lanes)           #shape = (1,40)\n",
    "#                 input_combine_x = input_combine_x.reshape(1,40)\n",
    "                \n",
    "#                 #add lane info of x-coordinate in input feature\n",
    "#                 temp_lane_arr = [0] * 1299\n",
    "#                 for k in range(1299):\n",
    "#                     if k == num_lanes:\n",
    "#                         break\n",
    "#                     temp_lane_arr[k] = input_lane[k,0]\n",
    "                \n",
    "#                 temp_input = input_combine_x.flatten()              \n",
    "#                 input_combine_x = np.append(temp_input,temp_lane_arr).reshape(1,1339) \n",
    "                \n",
    "                \n",
    "#                 #add lane norm info of x-coordinate in input feature\n",
    "#                 input_lane = data['lane_norm']\n",
    "#                 temp_lane_norm_arr = [0] * 1299\n",
    "#                 for k in range(1299):\n",
    "#                     if k == num_lanes:\n",
    "#                         break\n",
    "#                     temp_lane_norm_arr[k] = input_lane[k,0]            \n",
    "                \n",
    "#                 temp_input = input_combine_x.flatten()              \n",
    "#                 input_combine_x = np.append(temp_input,temp_lane_norm_arr).reshape(1,2638) \n",
    "                \n",
    "                \n",
    "                valid_x[i,:] = input_combine_x   \n",
    "                \n",
    "                output_data = data['p_out'][idx,:,:]\n",
    "                output_data1 = (output_data[:,0]).reshape(1,30)\n",
    "                valid_y[i,:] = output_data1\n",
    "            index += 1\n",
    "        if index == len(valid_list):\n",
    "            index = 0\n",
    "        yield valid_x, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator_y(training_list, batch_size):\n",
    "    index = 0\n",
    "    print(len(training_list))\n",
    "    while True:\n",
    "        train_x = np.empty((batch_size,38))\n",
    "        train_y = np.empty((batch_size,30))\n",
    "\n",
    "        for i in range(batch_size):            \n",
    "            train_path = training_list[index]\n",
    "            with open(train_path, 'rb') as f:\n",
    "                data = pickle.load(f)                \n",
    "                agent_id = data['agent_id']\n",
    "                idx = np.where(data[\"track_id\"] == data[\"agent_id\"])[0][0]\n",
    "                \n",
    "                # choose a random number between 0 and the target agent idx\n",
    "                idx = random.randint(0, idx)\n",
    "                \n",
    "                input_pos_in_data = data['p_in'][idx,:,:]                \n",
    "                input_pos_in_y = (input_pos_in_data[:,1]).reshape(1,19)\n",
    "#                 train_x[i,:] = input_pos_in_y\n",
    "    \n",
    "                #velocity\n",
    "                input_vel_in_data = data['v_in'][idx,:,:]                \n",
    "                input_vel_in_y = (input_vel_in_data[:,1]).reshape(1,19)\n",
    "                \n",
    "                #Combine position and velocity together into (1,38)\n",
    "                input_combine_y = np.concatenate((input_pos_in_y, input_vel_in_y), axis=0).reshape(1,38)\n",
    "                \n",
    "                #city\n",
    "#                 input_city = data['city']\n",
    "#                 if input_city == \"PIT\":\n",
    "#                     input_combine_y = np.append(input_combine_y, -1)\n",
    "#                 elif input_city == \"MIA\":\n",
    "#                     input_combine_y = np.append(input_combine_y, 1)\n",
    "                \n",
    "#                 #input_combine_y = input_combine_y.reshape(1,39)\n",
    "                \n",
    "                \n",
    "#                 #--------------------------Lane Info--------------------------\n",
    "                \n",
    "#                 # Find the closest lane with the corresponding lane_norm\n",
    "#                 input_lane = data['lane']\n",
    "#                 input_lane_norm = data['lane_norm']\n",
    "#                 num_lane = input_lane.shape[0]\n",
    "#                 closest_lane_idx = -2\n",
    "                \n",
    "#                 # Initialize distance = +inf\n",
    "#                 cur_distance = float('inf')\n",
    "                \n",
    "#                 # Start Iterating\n",
    "#                 for time_step in range(19):\n",
    "#                     for lane_idx in range(num_lane):\n",
    "#                         diff_x = data['p_in'][idx,time_step,0] - input_lane[lane_idx,0]\n",
    "#                         diff_y = data['p_in'][idx,time_step,1] - input_lane[lane_idx,1]\n",
    "#                         temp = diff_x ** 2 + diff_y ** 2\n",
    "#                         if temp < cur_distance:\n",
    "#                             cur_distance = temp\n",
    "#                             closest_lane_idx = lane_idx\n",
    "                    \n",
    "#                     #Put lane_y position and lane_y_velocity into the input feature \n",
    "#                     input_combine_y = np.append(input_combine_y, input_lane[closest_lane_idx,1])\n",
    "#                     input_combine_y = np.append(input_combine_y, input_lane_norm[closest_lane_idx,1])\n",
    "                    \n",
    "#                 #-----Now input feature shape = (1,77)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "#                 # add number of lanes in input feature \n",
    "#                 input_lane = data['lane']\n",
    "#                 num_lanes = input_lane.shape[0]     # num_lanes = k\n",
    "#                 input_combine_y = np.append(input_combine_y, num_lanes)           #shape = (1,40)\n",
    "#                 input_combine_y = input_combine_y.reshape(1,40)\n",
    "                \n",
    "                \n",
    "#                 #add lane info of y-coordinate in input feature\n",
    "#                 temp_lane_arr = [0] * 1299\n",
    "#                 for k in range(1299):\n",
    "#                     if k == num_lanes:\n",
    "#                         break\n",
    "#                     temp_lane_arr[k] = input_lane[k,1]\n",
    "                \n",
    "#                 temp_input = input_combine_y.flatten()              \n",
    "#                 input_combine_y = np.append(temp_input,temp_lane_arr).reshape(1,1339) \n",
    "                \n",
    "                \n",
    "#                 #add lane norm info of y-coordinate in input feature\n",
    "#                 input_lane = data['lane_norm']\n",
    "#                 temp_lane_norm_arr = [0] * 1299\n",
    "#                 for k in range(1299):\n",
    "#                     if k == num_lanes:\n",
    "#                         break\n",
    "#                     temp_lane_norm_arr[k] = input_lane[k,1]            \n",
    "                \n",
    "#                 temp_input = input_combine_y.flatten()              \n",
    "#                 input_combine_y = np.append(temp_input,temp_lane_norm_arr).reshape(1,2638) \n",
    "                \n",
    "            \n",
    "                train_x[i,:] = input_combine_y   #shape = (1,1339)   \n",
    "    \n",
    "    \n",
    "                output_pos_out_data = data['p_out'][idx,:,:]\n",
    "                output_pos_out_y = (output_pos_out_data[:,1]).reshape(1,30)\n",
    "                train_y[i,:] = output_pos_out_y\n",
    "            index += 1\n",
    "            \n",
    "        if index == len(training_list):\n",
    "            index = 0\n",
    "        yield train_x, train_y\n",
    "\n",
    "def valid_generator_y(valid_list, batch_size):\n",
    "    print(\"we are in vad\")\n",
    "    index = 0\n",
    "    while True:\n",
    "        valid_x = np.empty((batch_size,38))\n",
    "        valid_y = np.empty((batch_size,30))\n",
    "        for i in range(batch_size):\n",
    "            valid_path = valid_list[index]\n",
    "            with open(valid_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                agent_id = data['agent_id']\n",
    "                idx = np.where(data[\"track_id\"] == data[\"agent_id\"])[0][0]\n",
    "                \n",
    "                # choose a random number between 0 and the target agent idx\n",
    "                idx = random.randint(0, idx)\n",
    "                \n",
    "                input_data = data['p_in'][idx,:,:]\n",
    "                input_pos_in_y = (input_data[:,1]).reshape(1,19)\n",
    "#                 valid_x[i,:] = input_data1\n",
    "                \n",
    "                # add velocity\n",
    "                input_vel_in_data = data['v_in'][idx,:,:]                \n",
    "                input_vel_in_y = (input_vel_in_data[:,1]).reshape(1,19)\n",
    "                \n",
    "                #Combine position and velocity together into (1,38)\n",
    "                input_combine_y = np.concatenate((input_pos_in_y, input_vel_in_y), axis=0).reshape(1,38)\n",
    "                \n",
    "                # add city\n",
    "#                 input_city = data['city']\n",
    "#                 if input_city == \"PIT\":\n",
    "#                     input_combine_y = np.append(input_combine_y, -1)\n",
    "#                 elif input_city == \"MIA\":\n",
    "#                     input_combine_y = np.append(input_combine_y, 1)\n",
    "                    \n",
    "#                 #input_combine_y = input_combine_y.reshape(1,39)\n",
    "                    \n",
    "                    \n",
    "#                 #--------------------------Lane Info--------------------------\n",
    "                \n",
    "#                 # Find the closest lane with the corresponding lane_norm\n",
    "#                 input_lane = data['lane']\n",
    "#                 input_lane_norm = data['lane_norm']\n",
    "#                 num_lane = input_lane.shape[0]\n",
    "#                 closest_lane_idx = -2\n",
    "                \n",
    "#                 # Initialize distance = +inf\n",
    "#                 cur_distance = float('inf')\n",
    "                \n",
    "#                 # Start Iterating\n",
    "#                 for time_step in range(19):\n",
    "#                     for lane_idx in range(num_lane):\n",
    "#                         diff_x = data['p_in'][idx,time_step,0] - input_lane[lane_idx,0]\n",
    "#                         diff_y = data['p_in'][idx,time_step,1] - input_lane[lane_idx,1]\n",
    "#                         temp = diff_x ** 2 + diff_y ** 2\n",
    "#                         if temp < cur_distance:\n",
    "#                             cur_distance = temp\n",
    "#                             closest_lane_idx = lane_idx\n",
    "                    \n",
    "#                     #Put lane_y position and lane_y_velocity into the input feature \n",
    "#                     input_combine_y = np.append(input_combine_y, input_lane[closest_lane_idx,1])\n",
    "#                     input_combine_y = np.append(input_combine_y, input_lane_norm[closest_lane_idx,1])\n",
    "                    \n",
    "#                 #-----Now input feature shape = (1,77)   \n",
    "                \n",
    "                \n",
    "            \n",
    "#                 # add number of lanes in input feature \n",
    "#                 input_lane = data['lane']\n",
    "#                 num_lanes = input_lane.shape[0]     # num_lanes = k\n",
    "#                 input_combine_y = np.append(input_combine_y, num_lanes)           #shape = (1,40)\n",
    "#                 input_combine_y = input_combine_y.reshape(1,40)\n",
    "                \n",
    "                \n",
    "#                 #add lane info of y-coordinate in input feature\n",
    "#                 temp_lane_arr = [0] * 1299\n",
    "#                 for k in range(1299):\n",
    "#                     if k == num_lanes:\n",
    "#                         break\n",
    "#                     temp_lane_arr[k] = input_lane[k,1]\n",
    "                \n",
    "#                 temp_input = input_combine_y.flatten()              \n",
    "#                 input_combine_y = np.append(temp_input,temp_lane_arr).reshape(1,1339)    \n",
    "                \n",
    "                \n",
    "                \n",
    "#                 #add lane norm info of y-coordinate in input feature\n",
    "#                 input_lane = data['lane_norm']\n",
    "#                 temp_lane_norm_arr = [0] * 1299\n",
    "#                 for k in range(1299):\n",
    "#                     if k == num_lanes:\n",
    "#                         break\n",
    "#                     temp_lane_norm_arr[k] = input_lane[k,1]            \n",
    "                \n",
    "#                 temp_input = input_combine_y.flatten()              \n",
    "#                 input_combine_y = np.append(temp_input,temp_lane_norm_arr).reshape(1,2638) \n",
    "                \n",
    "                valid_x[i,:] = input_combine_y \n",
    "                \n",
    "                \n",
    "                output_data = data['p_out'][idx,:,:]\n",
    "                output_data1 = (output_data[:,1]).reshape(1,30)\n",
    "                valid_y[i,:] = output_data1\n",
    "            index += 1\n",
    "        if index == len(valid_list):\n",
    "            index = 0\n",
    "        yield valid_x, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205942\n",
      "205942\n",
      "185300\n",
      "20500\n"
     ]
    }
   ],
   "source": [
    "data_list = glob(os.path.join(train_path, '*'))\n",
    "random.shuffle(data_list)\n",
    "print(int(len(data_list)*1))\n",
    "data_list = data_list[:len(data_list)]\n",
    "print(int(len(data_list)*1))\n",
    "\n",
    "train_list = data_list[:int(len(data_list)*0.9)-47]\n",
    "valid_list = data_list[int(len(data_list)*0.9)+95:]\n",
    "print(len(train_list))\n",
    "print(len(valid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model structure\n",
    "#input shape (38) = 19x2\n",
    "#output shape(60) = 30x2\n",
    "\n",
    "model_x = Sequential()\n",
    "model_x.add(Input(shape=(38)))\n",
    "model_x.add(Dense(units=512, activation='elu'))\n",
    "model_x.add(Dense(units=512, activation='elu'))\n",
    "model_x.add(Dense(units=30, activation='linear'))\n",
    "\n",
    "model_y = Sequential()\n",
    "model_y.add(Input(shape=(38)))\n",
    "model_y.add(Dense(units=512, activation='elu'))\n",
    "model_y.add(Dense(units=512, activation='elu'))\n",
    "model_y.add(Dense(units=30, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "model_x.compile(loss=root_mean_squared_error, optimizer='adam')\n",
    "checkpointer_x = ModelCheckpoint(filepath='./liner_regressor_x_weights.hdf5', verbose=2, save_best_only=True, mode='min')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_y.compile(loss=root_mean_squared_error, optimizer='adam')\n",
    "checkpointer_y = ModelCheckpoint(filepath='./liner_regressor_y_weights.hdf5', verbose=2, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    }
   ],
   "source": [
    "batch_s = 20\n",
    "print('training...')\n",
    "num_train = len(train_list)/batch_s\n",
    "num_test = len(valid_list)/batch_s\n",
    "maxLane = 0\n",
    "train_gen_x = train_generator_x(train_list,batch_s)\n",
    "valid_gen_x = valid_generator_x(valid_list,batch_s)\n",
    "\n",
    "train_gen_y = train_generator_y(train_list,batch_s)\n",
    "valid_gen_y = valid_generator_y(valid_list,batch_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9430fbf4524bad8c2a8b92167b09df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e577e84b4d941238c149b2b0ff1b643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9265.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are in vad\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 8.55817, saving model to ./liner_regressor_x_weights.hdf5\n",
      "9265/9265 - 388s - loss: 20.8956 - val_loss: 8.5582\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist_x=model_x.fit(train_gen_x,\n",
    "                        verbose=2,\n",
    "                        epochs=1,\n",
    "                        validation_data=valid_gen_x,\n",
    "                        steps_per_epoch=(len(train_list)/batch_s),\n",
    "                        validation_steps=(len(valid_list)/batch_s),\n",
    "                        callbacks=[checkpointer_x,TqdmCallback(verbose=2)]\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               19968     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 298,014\n",
      "Trainable params: 298,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de91da193734e41b57d760cd426325f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717ed90158fc423db9928290469a4a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9265.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are in vad\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 15.75695, saving model to ./liner_regressor_y_weights.hdf5\n",
      "9265/9265 - 391s - loss: 21.9175 - val_loss: 15.7570\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist_y=model_y.fit(train_gen_y,\n",
    "                        verbose=2,\n",
    "                        epochs=1,\n",
    "                        validation_data=valid_gen_y,\n",
    "                        steps_per_epoch=(len(train_list)/batch_s),\n",
    "                        validation_steps=(len(valid_list)/batch_s),\n",
    "                        callbacks=[checkpointer_y,TqdmCallback(verbose=2)]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               19968     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 298,014\n",
      "Trainable params: 298,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_y.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drawing the training process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Attempting to set identical left == right == 1 results in singular transformations; automatically expanding.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = 1\n",
    "TrainERR=hist_x.history['loss']\n",
    "ValidERR=hist_x.history['val_loss']\n",
    "# print('@%f, Minimun error:%f, at iteration: %i' % (hist.history['val_loss'][epoch-1], np.min(np.asarray(ValidERR)),np.argmin(np.asarray(ValidERR))+1))\n",
    "print('drawing the training process...')\n",
    "plt.figure(2)\n",
    "plt.plot(range(1,epoch+1),TrainERR,'b',label='TrainERR')\n",
    "plt.plot(range(1,epoch+1),ValidERR,'r',label='ValidERR')\n",
    "plt.xlim([1,epoch])\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drawing the training process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Attempting to set identical left == right == 1 results in singular transformations; automatically expanding.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = 1\n",
    "TrainERR=hist_y.history['loss']\n",
    "ValidERR=hist_y.history['val_loss']\n",
    "# print('@%f, Minimun error:%f, at iteration: %i' % (hist.history['val_loss'][epoch-1], np.min(np.asarray(ValidERR)),np.argmin(np.asarray(ValidERR))+1))\n",
    "print('drawing the training process...')\n",
    "plt.figure(2)\n",
    "plt.plot(range(1,epoch+1),TrainERR,'b',label='TrainERR')\n",
    "plt.plot(range(1,epoch+1),ValidERR,'r',label='ValidERR')\n",
    "plt.xlim([1,epoch])\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max lanes: \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"max lanes: \")\n",
    "print(maxLane)\n",
    "\n",
    "#max # of lanes = 1899 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "columns.append(\"ID\")\n",
    "for i in range(30):\n",
    "    num = \"v\"+str(i+1)\n",
    "    columns.append(num)\n",
    "    \n",
    "df_x = pd.DataFrame(columns=columns)\n",
    "df_y = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>v29</th>\n",
       "      <th>v30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13, v14, v15, v16, v17, v18, v19, v20, v21, v22, v23, v24, v25, v26, v27, v28, v29, v30]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>v29</th>\n",
       "      <th>v30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13, v14, v15, v16, v17, v18, v19, v20, v21, v22, v23, v24, v25, v26, v27, v28, v29, v30]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 31 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/s1kan/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /home/s1kan/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/s1kan/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/s1kan/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/s1kan/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /home/s1kan/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /home/s1kan/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 38 but received input with shape [None, 39]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-11cd5f3a4454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mtest_pos_out_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_combine_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m#         print(test_pos_out_x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/s1kan/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /home/s1kan/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/s1kan/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/s1kan/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/s1kan/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /home/s1kan/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /home/s1kan/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 38 but received input with shape [None, 39]\n"
     ]
    }
   ],
   "source": [
    "test_list = glob(os.path.join(test_path, '*'))\n",
    "print(len(test_list))\n",
    "\n",
    "#correct\n",
    "for x in tqdm(test_list):\n",
    "    test_pos_in_x = np.empty((1,19))\n",
    "    with open(x, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        new_row = []\n",
    "        scene_id = data['scene_idx']     # new_row = [scene_idx]\n",
    "        new_row.append(scene_id)\n",
    "        agent_id = data['agent_id']\n",
    "        idx = np.where(data[\"track_id\"] == data[\"agent_id\"])[0][0]   \n",
    "        \n",
    "        \n",
    "        #Position\n",
    "        input_data_pos = data['p_in'][idx,:,:]     #data['p_in'] = (vehicle_idx, timestep, coordinate axis)\n",
    "        test_pos_in_x[0,:] = (input_data_pos[:,0]).reshape(1,19)\n",
    "\n",
    "        \n",
    "        test_vel_in_x = np.empty((1,19))\n",
    "        #Velocity\n",
    "        input_data_vel_x = data['v_in'][idx,:,:]     \n",
    "        test_vel_in_x[0,:] = (input_data_vel_x[:,0]).reshape(1,19)\n",
    "        \n",
    "        #Combine position and velocity together into (1,38)\n",
    "        input_combine_x = np.concatenate((test_pos_in_x, test_vel_in_x), axis=0).reshape(1,38)\n",
    "\n",
    "        # add city\n",
    "        input_city = data['city']\n",
    "        if input_city == \"PIT\":\n",
    "            input_combine_x = np.append(input_combine_x, -1)\n",
    "        elif input_city == \"MIA\":\n",
    "            input_combine_x = np.append(input_combine_x, 1)\n",
    "        \n",
    "    \n",
    "#         print(input_combine_x)\n",
    "#         # Find the closest lane with the corresponding lane_norm\n",
    "#         input_lane = data['lane']\n",
    "#         input_lane_norm = data['lane_norm']\n",
    "#         num_lane = input_lane.shape[0]\n",
    "#         closest_lane_idx = -2\n",
    "\n",
    "#         # Initialize distance = +inf\n",
    "#         cur_distance = float('inf')\n",
    "\n",
    "#         # Start Iterating\n",
    "#         for time_step in range(19):\n",
    "#             for lane_idx in range(num_lane):\n",
    "#                 diff_x = data['p_in'][idx,time_step,0] - input_lane[lane_idx,0]\n",
    "#                 diff_y = data['p_in'][idx,time_step,1] - input_lane[lane_idx,1]\n",
    "#                 temp = diff_x ** 2 + diff_y ** 2\n",
    "#                 if temp < cur_distance:\n",
    "#                     cur_distance = temp\n",
    "#                     closest_lane_idx = lane_idx\n",
    "\n",
    "#             #Put lane_y position and lane_y_velocity into the input feature \n",
    "#             input_combine_x = np.append(input_combine_x, input_lane[closest_lane_idx,0])\n",
    "#             input_combine_x = np.append(input_combine_x, input_lane_norm[closest_lane_idx,0])\n",
    "\n",
    "#          #-----Now input feature shape = (1,77)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        input_combine_x = input_combine_x.reshape(1,39)\n",
    "        \n",
    "#         # add number of lanes in input feature \n",
    "#         input_lane = data['lane']\n",
    "#         num_lanes = input_lane.shape[0]     # num_lanes = k\n",
    "#         input_combine_x = np.append(input_combine_x, num_lanes)           #shape = (1,40)\n",
    "#         input_combine_x = input_combine_x.reshape(1,40)\n",
    "        \n",
    "        \n",
    "        test_pos_out_x = model_x.predict(input_combine_x)\n",
    "\n",
    "#         print(test_pos_out_x)\n",
    "        for i in range(30):\n",
    "            new_row.append(test_pos_out_x[0][i])   # new_row = [scene_idx, p_out_x1, p_out_x2 ..., p_out_x30]\n",
    "            \n",
    "        df_length = len(df_x)              # len(df_x) is the number of rows in the current dataFrame\n",
    "        df_x.loc[df_length] = new_row\n",
    "\n",
    "        \n",
    "        \n",
    "for x in tqdm(test_list):\n",
    "    test_pos_in_y = np.empty((1,19))\n",
    "    with open(x, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        new_row = []\n",
    "        scene_id = data['scene_idx']\n",
    "        new_row.append(scene_id)\n",
    "        agent_id = data['agent_id']\n",
    "        idx = np.where(data[\"track_id\"] == data[\"agent_id\"])[0][0]   \n",
    "        \n",
    "        #Position\n",
    "        input_data_pos = data['p_in'][idx,:,:]\n",
    "        test_pos_in_y[0,:] = (input_data_pos[:,1]).reshape(1,19)\n",
    "        \n",
    "        test_vel_in_y = np.empty((1,19))\n",
    "        #Velocity\n",
    "        input_data_vel_y = data['v_in'][idx,:,:]     \n",
    "        test_vel_in_y[0,:] = (input_data_vel_y[:,1]).reshape(1,19)\n",
    "        \n",
    "        #Combine position and velocity together into (1,38)\n",
    "        input_combine_y = np.concatenate((test_pos_in_y, test_vel_in_y), axis=0).reshape(1,38)\n",
    "        \n",
    "        # add city\n",
    "        input_city = data['city']\n",
    "        if input_city == \"PIT\":\n",
    "            input_combine_y = np.append(input_combine_y, -1)\n",
    "        elif input_city == \"MIA\":\n",
    "            input_combine_y = np.append(input_combine_y, 1)\n",
    "        \n",
    "        \n",
    "#         # Find the closest lane with the corresponding lane_norm\n",
    "#         input_lane = data['lane']\n",
    "#         input_lane_norm = data['lane_norm']\n",
    "#         num_lane = input_lane.shape[0]\n",
    "#         closest_lane_idx = -2\n",
    "\n",
    "#         # Initialize distance = +inf\n",
    "#         cur_distance = float('inf')\n",
    "\n",
    "#         # Start Iterating\n",
    "#         for time_step in range(19):\n",
    "#             for lane_idx in range(num_lane):\n",
    "#                 diff_x = data['p_in'][idx,time_step,0] - input_lane[lane_idx,0]\n",
    "#                 diff_y = data['p_in'][idx,time_step,1] - input_lane[lane_idx,1]\n",
    "#                 temp = diff_x ** 2 + diff_y ** 2\n",
    "#                 if temp < cur_distance:\n",
    "#                     cur_distance = temp\n",
    "#                     closest_lane_idx = lane_idx\n",
    "\n",
    "#             #Put lane_y position and lane_y_velocity into the input feature \n",
    "#             input_combine_y = np.append(input_combine_y, input_lane[closest_lane_idx,1])\n",
    "#             input_combine_y = np.append(input_combine_y, input_lane_norm[closest_lane_idx,1])\n",
    "                    \n",
    "#         #-----Now input feature shape = (1,77)\n",
    "        \n",
    "        input_combine_y = input_combine_y.reshape(1,39)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         # add number of lanes in input feature \n",
    "#         input_lane = data['lane']\n",
    "#         num_lanes = input_lane.shape[0]     # num_lanes = k\n",
    "#         input_combine_y = np.append(input_combine_y, num_lanes)           #shape = (1,40)\n",
    "#         input_combine_y = input_combine_y.reshape(1,40)\n",
    "        \n",
    "        test_pos_out_y = model_y.predict(input_combine_y)\n",
    "\n",
    "        for i in range(30):\n",
    "            new_row.append(test_pos_out_y[0][i])\n",
    "            \n",
    "        df_length = len(df_y)\n",
    "        df_y.loc[df_length] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['ID'] = df_x['ID'].map(round)\n",
    "df_y['ID'] = df_y['ID'].map(round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_x    #predicted p_out_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y   # predicted p_out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_sub = []\n",
    "columns_sub.append(\"ID\")\n",
    "for i in range(60):\n",
    "    num = \"v\"+str(i+1)\n",
    "    columns_sub.append(num)\n",
    "    \n",
    "df_sub = pd.DataFrame(columns=columns_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.iloc[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.iloc[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_x.shape[0]):\n",
    "    row_x = df_x.iloc[i]\n",
    "    row_y = df_y.iloc[i]\n",
    "    new_row = []\n",
    "    new_row.append(row_x[0])\n",
    "    for i in range(1,31):\n",
    "        new_row.append(row_x[i])\n",
    "        new_row.append(row_y[i])\n",
    "    df_length = len(df_sub)\n",
    "    df_sub.loc[df_length] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['ID'] = df_sub['ID'].map(round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(r'./submissions_old.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_test = []\n",
    "columns_test.append(\"ID\")\n",
    "for i in range(38):\n",
    "    num = \"v\"+str(i+1)\n",
    "    columns_test.append(num)\n",
    "    \n",
    "df_test = pd.DataFrame(columns=columns_test)\n",
    "\n",
    "\n",
    "for x in test_list:\n",
    "    with open(x, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        new_row = []\n",
    "        scene_id = data['scene_idx']\n",
    "        new_row.append(scene_id)\n",
    "        agent_id = data['agent_id']\n",
    "        idx = np.where(data[\"track_id\"] == data[\"agent_id\"])[0][0]   \n",
    "        input_data = data['p_in'][idx,:,:]\n",
    "        for i in range(38):\n",
    "            new_row.append(input_data.flatten()[i])\n",
    "        df_length = len(df_test)\n",
    "        df_test.loc[df_length] = new_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(test_list[len(test_list)-1], 'rb') as f:\n",
    "#         data = pickle.load(f)\n",
    "#         new_row = []\n",
    "#         scene_id = data['scene_idx']\n",
    "#         new_row.append(scene_id)\n",
    "#         agent_id = data['agent_id']\n",
    "#         idx = np.where(data[\"track_id\"] == data[\"agent_id\"])[0][0]   \n",
    "#         input_data = data['p_in'][idx,:,:]\n",
    "# #         print(\"shape of input data \", input_data.flatten().shape)\n",
    "#         print(input_data.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vis_list = train_list[:3]\n",
    "time_arr = []\n",
    "for i in range(30):\n",
    "    time_arr.append(i)\n",
    "\n",
    "\n",
    "for i,x in enumerate(vis_list):\n",
    "    with open(x, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        new_row = []\n",
    "        scene_id = data['scene_idx']\n",
    "        new_row.append(scene_id)\n",
    "        agent_id = data['agent_id']\n",
    "        idx = np.where(data[\"track_id\"] == data[\"agent_id\"])[0][0]   \n",
    "        \n",
    "        #---------Position----------------\n",
    "        input_data_pos = data['p_in'][idx,:,:]\n",
    "        input_x_pos = input_data_pos[:,0]\n",
    "        input_y_pos = input_data_pos[:,1]\n",
    "           \n",
    "        #---------Velocity----------------\n",
    "        input_data_vel = data['v_in'][idx,:,:]\n",
    "        input_x_vel = input_data_vel[:,0]\n",
    "        input_y_vel = input_data_vel[:,1]\n",
    "                \n",
    "        \n",
    "        #Combine position and velocity together into (1,38)\n",
    "        input_combine_x = np.concatenate((input_x_pos, input_x_vel), axis=0).reshape(1,38)\n",
    "        input_combine_y = np.concatenate((input_y_pos, input_y_vel), axis=0).reshape(1,38)       \n",
    "        \n",
    "        #--------City-----------------\n",
    "        input_city = data['city']\n",
    "        if input_city == \"PIT\":\n",
    "            input_combine_x = np.append(input_combine_x, -1)\n",
    "            input_combine_y = np.append(input_combine_y, -1)\n",
    "        elif input_city == \"MIA\":\n",
    "            input_combine_x = np.append(input_combine_x, 1)\n",
    "            input_combine_y = np.append(input_combine_y, 1)\n",
    "        \n",
    "        input_combine_x = input_combine_x.reshape(1,39)\n",
    "        input_combine_y = input_combine_y.reshape(1,39)        \n",
    "        \n",
    "           \n",
    "#         input_x = input_x.reshape(1,19)\n",
    "        pred_x = model_x(input_combine_x).numpy().reshape(30,1)\n",
    "        pred_y = model_y(input_combine_y).numpy().reshape(30,1)\n",
    "        \n",
    "#         print(pred_x)\n",
    "        #----------Prediction----------------\n",
    "        time_arr = []\n",
    "        for t in range(30):\n",
    "            time_arr.append(t+1)\n",
    "            \n",
    "        plt.xlabel('timestamps')\n",
    "        plt.ylabel('X position')\n",
    "        plt.plot(time_arr, pred_x, label = \"prediction x position\")\n",
    "#         break\n",
    "        #-----------Ground Truth-------------\n",
    "        output_data = data['p_out'][idx,:,:]\n",
    "#         gt_x = output_data[:,0].reshape(1,30)\n",
    "        gt_x = output_data[:,0]\n",
    "#         gt_y = output_data[:,1].reshape(1,30)    \n",
    "        gt_y = output_data[:,1]\n",
    "       \n",
    "        plt.xlabel('timestamps')\n",
    "        plt.ylabel('X position')\n",
    "        plt.plot(time_arr, gt_x, label = \"ground truth x position\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(time_arr, pred_y, label = \"prediction y position\")\n",
    "        plt.plot(time_arr, gt_y, label = \"ground truth y position\")      \n",
    "        plt.xlabel('timestamps')\n",
    "        plt.ylabel('Y position')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()       \n",
    "        \n",
    "        print(\"-------------------------------------------\")\n",
    "\n",
    "        \n",
    "#         input_y = input_y.reshape(1,19)\n",
    "#         pred_y = model_y(input_y)\n",
    "#         print(pred_y.shape)\n",
    "#         print(pred_y)\n",
    "#         output_data = data['p_out'][idx,:,:]\n",
    "#         gt_x = output_data[:,0].reshape(1,30)\n",
    "#         print(gt_x.shape)\n",
    "#         print(gt_x)\n",
    "#         #gt_x = output_data.reshape(1,30)\n",
    "#         #gt_y = output_data.reshape(1,30)\n",
    "#         plt.figure(i)\n",
    "#         print(time_arr)\n",
    "        \n",
    "#         fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "#         #plt.title('Test example ' + str(thres) + ': ' + line.split(\"/\")[-2] + \"/\" +line.split(\"/\")[-1])\n",
    "#         plt.title('Test example: ')\n",
    "#         ax1.plot(time_arr, gt_x, '-g', label='gt')\n",
    "#         ax1.plot(time_arr, pred_x, ':b', label='pred')\n",
    "#         ax1.set(xlabel='timestamp', ylabel='position')\n",
    "#         ax1.set_title('X position sample',str(i))\n",
    "        \n",
    "#         ax2.plot(time_arr, gt_y, '-g', label='gt')\n",
    "#         ax2.plot(time_arr, pred_y, ':b', label='pred')\n",
    "#         ax2.set(xlabel='timestamp', ylabel='position')\n",
    "#         ax2.set_title('y position sample',str(i))\n",
    "#         plt.legend();\n",
    "#         plt.show()\n",
    "#         fig1 = plt.gcf()\n",
    "#         saving_path = \"sample\" + str(i)\n",
    "#         fig1.savefig(saving_path + '.png', dpi=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
